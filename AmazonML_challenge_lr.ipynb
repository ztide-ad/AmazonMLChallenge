{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tlhyxQElehlyXkFXJqNJCAP1Ill4N7Oh",
      "authorship_tag": "ABX9TyPGS4JM681648ue9NSELgTJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ztide-ad/AmazonMLChallenge/blob/main/AmazonML_challenge_lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTyV5kpb9x2e",
        "outputId": "4545f778-23fc-4c13-ab5a-a4ac4965a509"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bCFwY-JL82Bw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import pytesseract\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import re\n",
        "import requests\n",
        "import multiprocessing\n",
        "import time\n",
        "from time import time as timer\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "import urllib\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhGIyusE86QB",
        "outputId": "d6900755-7920-4a1a-ccc6-75d3c265a4c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_units = [\n",
        "    'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard',\n",
        "    'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton',\n",
        "    'kilovolt', 'millivolt', 'volt',\n",
        "    'kilowatt', 'watt',\n",
        "    'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce',\n",
        "    'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'\n",
        "]"
      ],
      "metadata": {
        "id": "J927gQZp_Fk5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def common_mistake(unit):\n",
        "    if unit in allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def parse_string(s):\n",
        "    s_stripped = \"\" if s is None or str(s) == 'nan' else s.strip()\n",
        "    if s_stripped == \"\":\n",
        "        return None, None\n",
        "\n",
        "    # Handle range values\n",
        "    range_pattern = re.compile(r'^\\[(\\d+(\\.\\d+)?),\\s*(\\d+(\\.\\d+)?)\\]\\s+([a-zA-Z\\s]+)$')\n",
        "    range_match = range_pattern.match(s_stripped)\n",
        "\n",
        "    if range_match:\n",
        "        # For ranges, we'll use the average of the two values\n",
        "        start, end = float(range_match.group(1)), float(range_match.group(3))\n",
        "        number = (start + end) / 2\n",
        "        unit = range_match.group(5)\n",
        "    else:\n",
        "        # Original pattern for single values\n",
        "        pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
        "        if not pattern.match(s_stripped):\n",
        "            raise ValueError(f\"Invalid format in {s}\")\n",
        "        parts = s_stripped.split(maxsplit=1)\n",
        "        number = float(parts[0])\n",
        "        unit = parts[1]\n",
        "\n",
        "    unit = common_mistake(unit)\n",
        "    if unit not in allowed_units:\n",
        "        raise ValueError(f\"Invalid unit [{unit}] found in {s}. Allowed units: {allowed_units}\")\n",
        "\n",
        "    return number, unit\n",
        "\n",
        "def common_mistake(unit):\n",
        "    if unit in allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def create_placeholder_image(image_save_path):\n",
        "    try:\n",
        "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
        "        placeholder_image.save(image_save_path)\n",
        "    except Exception as e:\n",
        "        return\n",
        "\n",
        "def download_image(image_link, save_folder, retries=3, delay=3):\n",
        "    if not isinstance(image_link, str):\n",
        "        return\n",
        "\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return\n",
        "\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)\n",
        "            return\n",
        "        except:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
        "\n",
        "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    if allow_multiprocessing:\n",
        "        download_image_partial = partial(\n",
        "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
        "\n",
        "        with multiprocessing.Pool(64) as pool:\n",
        "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "    else:\n",
        "        for image_link in tqdm(image_links, total=len(image_links)):\n",
        "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)"
      ],
      "metadata": {
        "id": "S4qwV0WE94GI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(csv_path, num_samples=1000):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    return df.sample(n=num_samples, random_state=42)\n",
        "\n",
        "train_df = load_data('/content/drive/MyDrive/AmazonML/dataset/train.csv', num_samples=1000)"
      ],
      "metadata": {
        "id": "DUa69-IXAJR6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = '/content/drive/MyDrive/AmazonML/dataset/images'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "download_images(train_df['image_link'], image_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFI4AZmob0Z7",
        "outputId": "a24c00de-1366-405d-e79d-afc7659b956f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:01<00:00, 868.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "JOn-OvhhAe4N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_ocr(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    return pytesseract.image_to_string(image)"
      ],
      "metadata": {
        "id": "hZtK4L-7aVfk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
        "    img_path = os.path.join(image_folder, row['image_link'].split('/')[-1])\n",
        "    if os.path.exists(img_path):\n",
        "        ocr_text = perform_ocr(img_path)\n",
        "        combined_text = f\"{ocr_text} {row['entity_name']}\"\n",
        "        texts.append(combined_text)\n",
        "\n",
        "        unit = row['entity_value'].split()[-1]  # Assuming the unit is always the last word\n",
        "        if unit in allowed_units:\n",
        "            labels.append(allowed_units.index(unit))\n",
        "        else:\n",
        "            labels.append(-1)  # Unknown unit"
      ],
      "metadata": {
        "id": "8O9Yerl9BJkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98683ce4-04a1-47b3-a0ea-6dba678fcd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 404/1000 [08:25<14:49,  1.49s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = texts\n",
        "y = [label for label in labels if label != -1]\n",
        "X = [text for text, label in zip(X, labels) if label != -1]"
      ],
      "metadata": {
        "id": "fni8uhVMBLKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "TVenplm5BPpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "IaxDLOOOBSNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(multi_class='ovr', max_iter=2500)\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "id": "tn24G7eKBV4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model.predict(X_train_tfidf)\n",
        "y_test_pred = model.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "5Mk4ZVU1uo4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
        "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
        "\n",
        "print(f\"Train F1 score: {train_f1:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "Gh13XiXkC6Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report for Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=allowed_units))"
      ],
      "metadata": {
        "id": "aFrzd5lFRVE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict unit for a new image\n",
        "def predict_unit(image_path, entity_name):\n",
        "    ocr_text = perform_ocr(image_path)\n",
        "    combined_text = f\"{ocr_text} {entity_name}\"\n",
        "    features = vectorizer.transform([combined_text])\n",
        "    predicted_index = model.predict(features)[0]\n",
        "    return allowed_units[predicted_index]"
      ],
      "metadata": {
        "id": "XNK1dTODCgr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a sample image\n",
        "sample_image_path = '/content/drive/MyDrive/AmazonML/dataset/images/7185b+0uzML.jpg'\n",
        "sample_entity_name = 'item_weight'\n",
        "predicted_unit = predict_unit(sample_image_path, sample_entity_name)\n",
        "print(f\"Predicted unit for {sample_entity_name}: {predicted_unit}\")"
      ],
      "metadata": {
        "id": "W-vLbT1ADHpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXReUYQdEiCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}