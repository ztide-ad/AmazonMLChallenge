{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1tlhyxQElehlyXkFXJqNJCAP1Ill4N7Oh",
      "authorship_tag": "ABX9TyNitfRrkgvfZzo18epee8wz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ztide-ad/AmazonMLChallenge/blob/main/AmazonML_challenge_adv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTyV5kpb9x2e",
        "outputId": "d8e1fd39-956d-4065-a175-835e784e8ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCFwY-JL82Bw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytesseract\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import requests\n",
        "import multiprocessing\n",
        "import time\n",
        "from time import time as timer\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "import urllib\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "P4uH3jty-wcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhGIyusE86QB",
        "outputId": "2a1a9087-9e8e-4749-94bd-452eddf5c46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram',\n",
        "        'kilogram',\n",
        "        'microgram',\n",
        "        'milligram',\n",
        "        'ounce',\n",
        "        'pound',\n",
        "        'ton'},\n",
        "    'maximum_weight_recommendation': {'gram',\n",
        "        'kilogram',\n",
        "        'microgram',\n",
        "        'milligram',\n",
        "        'ounce',\n",
        "        'pound',\n",
        "        'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre',\n",
        "        'cubic foot',\n",
        "        'cubic inch',\n",
        "        'cup',\n",
        "        'decilitre',\n",
        "        'fluid ounce',\n",
        "        'gallon',\n",
        "        'imperial gallon',\n",
        "        'litre',\n",
        "        'microlitre',\n",
        "        'millilitre',\n",
        "        'pint',\n",
        "        'quart'}\n",
        "}\n",
        "\n",
        "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}"
      ],
      "metadata": {
        "id": "J927gQZp_Fk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def common_mistake(unit):\n",
        "    if unit in allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def parse_string(s):\n",
        "    s_stripped = \"\" if s is None or str(s) == 'nan' else s.strip()\n",
        "    if s_stripped == \"\":\n",
        "        return None, None\n",
        "\n",
        "    # Handle range values\n",
        "    range_pattern = re.compile(r'^\\[(\\d+(\\.\\d+)?),\\s*(\\d+(\\.\\d+)?)\\]\\s+([a-zA-Z\\s]+)$')\n",
        "    range_match = range_pattern.match(s_stripped)\n",
        "\n",
        "    if range_match:\n",
        "        # For ranges, we'll use the average of the two values\n",
        "        start, end = float(range_match.group(1)), float(range_match.group(3))\n",
        "        number = (start + end) / 2\n",
        "        unit = range_match.group(5)\n",
        "    else:\n",
        "        # Original pattern for single values\n",
        "        pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
        "        if not pattern.match(s_stripped):\n",
        "            raise ValueError(f\"Invalid format in {s}\")\n",
        "        parts = s_stripped.split(maxsplit=1)\n",
        "        number = float(parts[0])\n",
        "        unit = parts[1]\n",
        "\n",
        "    unit = common_mistake(unit)\n",
        "    if unit not in allowed_units:\n",
        "        raise ValueError(f\"Invalid unit [{unit}] found in {s}. Allowed units: {allowed_units}\")\n",
        "\n",
        "    return number, unit\n",
        "\n",
        "def common_mistake(unit):\n",
        "    if unit in allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def create_placeholder_image(image_save_path):\n",
        "    try:\n",
        "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
        "        placeholder_image.save(image_save_path)\n",
        "    except Exception as e:\n",
        "        return\n",
        "\n",
        "def download_image(image_link, save_folder, retries=3, delay=3):\n",
        "    if not isinstance(image_link, str):\n",
        "        return\n",
        "\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return\n",
        "\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)\n",
        "            return\n",
        "        except:\n",
        "            time.sleep(delay)\n",
        "\n",
        "    create_placeholder_image(image_save_path) #Create a black placeholder image for invalid links/images\n",
        "\n",
        "def download_images(image_links, download_folder, allow_multiprocessing=True):\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    if allow_multiprocessing:\n",
        "        download_image_partial = partial(\n",
        "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
        "\n",
        "        with multiprocessing.Pool(64) as pool:\n",
        "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "    else:\n",
        "        for image_link in tqdm(image_links, total=len(image_links)):\n",
        "            download_image(image_link, save_folder=download_folder, retries=3, delay=3)"
      ],
      "metadata": {
        "id": "S4qwV0WE94GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(csv_path, num_samples=1000):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    return df.sample(n=num_samples, random_state=42)\n",
        "\n",
        "train_df = load_data('/content/drive/MyDrive/AmazonML/dataset/train.csv', num_samples=1000)"
      ],
      "metadata": {
        "id": "DUa69-IXAJR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = '/content/drive/MyDrive/AmazonML/dataset/images'\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "download_images(train_df['image_link'], image_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOn-OvhhAe4N",
        "outputId": "b11d721f-ccb3-4449-b8d7-7d0cfd6e9a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1182.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_folder, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.image_folder = image_folder\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_folder, self.dataframe.iloc[idx]['image_link'].split('/')[-1])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        ocr_text = perform_ocr(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        entity_name = self.dataframe.iloc[idx]['entity_name']\n",
        "        entity_value = self.dataframe.iloc[idx]['entity_value']\n",
        "\n",
        "        return image, ocr_text, entity_name, entity_value"
      ],
      "metadata": {
        "id": "sNIZB5JxAnJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "8O9Yerl9BJkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ProductDataset(train_df, image_folder, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "fni8uhVMBLKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_ocr(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    return pytesseract.image_to_string(image)"
      ],
      "metadata": {
        "id": "TVenplm5BPpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP model (using a pre-trained model for sequence classification)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(allowed_units))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaxDLOOOBSNj",
        "outputId": "e19c5891-f12f-40e4-bb96-5e8c77647ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn24G7eKBV4v",
        "outputId": "cb5b768c-a389-4519-f4d7-2c10d567d344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=31, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change allowed_units to a list\n",
        "allowed_units = list(allowed_units)"
      ],
      "metadata": {
        "id": "Gh13XiXkC6Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-1)\n",
        "num_epochs = 1"
      ],
      "metadata": {
        "id": "aFrzd5lFRVE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, ocr_texts, entity_names, entity_values in tqdm(dataloader):\n",
        "        images = images.to(device)\n",
        "\n",
        "        # Combine OCR text and entity names\n",
        "        input_texts = [f\"{ocr} {name}\" for ocr, name in zip(ocr_texts, entity_names)]\n",
        "\n",
        "        # Tokenize input texts\n",
        "        inputs = tokenizer(input_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Parse entity values\n",
        "        labels = []\n",
        "        for val in entity_values:\n",
        "            try:\n",
        "                _, unit = parse_string(val)\n",
        "                if unit in allowed_units:\n",
        "                    labels.append(allowed_units.index(unit))\n",
        "                else:\n",
        "                    labels.append(-1)  # Use -1 as a label for unknown units\n",
        "            except ValueError:\n",
        "                labels.append(-1)  # Use -1 as a label for parsing errors\n",
        "\n",
        "        labels = torch.tensor(labels).to(device)\n",
        "\n",
        "        # Filter out samples with unknown units or parsing errors\n",
        "        valid_samples = labels != -1\n",
        "        if valid_samples.sum() > 0:\n",
        "            inputs = {k: v[valid_samples] for k, v in inputs.items()}\n",
        "            labels = labels[valid_samples]\n",
        "\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            print(\"No valid samples in this batch\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4XUlI4oBuq8",
        "outputId": "60195ccd-4dfd-4761-e52f-ba0090a57df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/32 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/AmazonML/model.pth')"
      ],
      "metadata": {
        "id": "zmkoK6aOB0T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_path, entity_name):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    ocr_text = perform_ocr(image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
        "    input_text = f\"{ocr_text} {entity_name}\"\n",
        "\n",
        "    inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predicted_unit_index = outputs.logits.argmax().item()\n",
        "    if predicted_unit_index < len(allowed_units):\n",
        "        predicted_unit = list(allowed_units)[predicted_unit_index]\n",
        "        return predicted_unit\n",
        "    else:\n",
        "        return \"Unknown unit\""
      ],
      "metadata": {
        "id": "XNK1dTODCgr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on a sample image\n",
        "sample_image_path = '/content/drive/MyDrive/AmazonML/dataset/images/81u23a-tF-L.jpg'\n",
        "sample_entity_name = 'item_weight'\n",
        "predicted_unit = predict(sample_image_path, sample_entity_name)\n",
        "print(f\"Predicted unit for {sample_entity_name}: {predicted_unit}\")"
      ],
      "metadata": {
        "id": "W-vLbT1ADHpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXReUYQdEiCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}